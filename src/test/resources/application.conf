# For the purpose of testing - the formulations here are correct based on the
# Step specification

include "workflows.conf"

jobs : [
  {
    id : 0
    name : "99 beers on the wall."
    description : "99 beers on the wall."
    workdir : ${?HOME}"/working_dir"
    workdir : ${?JOB_WORK_DIR}
    sessionid : "TEST_ID_0"
    sessionid : ${?SESSION_ID}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Dataflow:python"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
  
    inputs : [
      ${jobgraph.settings.urls.0}":local_file"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.1}":local_file"
    ]
  }
]
jobs2 : [
  {
    id : 1
    name : "98 beers on the wall"
    description : "98 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_1"
    sessionid: ${?SESSION_ID}
    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Dataflow:java"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }

    inputs : [
      ${jobgraph.settings.urls.2}":local_file"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.3}":local_file"
    ]
  }
]
jobs3 : [

  {
    id : 2
    name : "97 beers on the wall"
    description : "97 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_2"
    sessionid: ${?SESSION_ID}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Dataflow:java"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
 
    inputs : [
      ${jobgraph.settings.urls.4}":local_file2"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.5}":local_file2"
    ]
  },

  {
    id : 3
    name : "96 beers on the wall"
    description : "96 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Dataflow:python"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
  
    inputs : [
      ${jobgraph.settings.urls.6}":local_file3"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.7}":local_file3"
    ]
  }
]

jobs4 : [

  {
    id : 4
    name : "97 beers on the wall"
    description : "97 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_2"
    sessionid: ${?SESSION_ID}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Flink:haskell"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
 
    inputs : [
      ${jobgraph.settings.urls.4}":local_file2"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.5}":local_file2"
    ]
  },

  {
    id : 5
    name : "96 beers on the wall"
    description : "96 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Dataflow:"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
  
    inputs : [
      ${jobgraph.settings.urls.6}":local_file3"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.7}":local_file3"
    ]
  },

  {
    id : 6
    name : "96 beers on the wall"
    description : "96 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : ":java"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
  
    inputs : [
      ${jobgraph.settings.urls.6}":local_file3"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.7}":local_file3"
    ]
  },

  {
    id : 7
    name : "96 beers on the wall"
    description : "96 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : "Dataflow:haskell"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
  
    inputs : [
      ${jobgraph.settings.urls.6}":local_file3"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.7}":local_file3"
    ]
  },

  {
    id : 8
    name : "96 beers on the wall"
    description : "96 beers on the wall"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}

    runner {
     module : "apache_beam.examples.wordcount"
     runner : ":"
     cliargs : ["--jobName bloody-google-dataflow",
                "--input gs://hicoden/README.md",
                "--output gs://hicoden-test-1/XX",
                "--runner DataflowRunner",
                "--project hicoden",
                "--temp_location gs://hicoden-test-1/",
                "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
               ]
    }
  
    inputs : [
      ${jobgraph.settings.urls.6}":local_file3"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.7}":local_file3"
    ]
  },

]

workflows : [
  {
    id : 0
    name : "A sample process"
    description : "Reads from file, processed them and finally read them"
    steps : [0,1,2,3]
    jobgraph : [
      "0 -> 1",
      "0 -> 2",
      "2 -> 3",
      "1 -> 3"
    ]
  }
]

workflows2 : [
  {
    id : 1
    name : "Another sample process"
    description : "Reads from file, processed them and finally read them"
    steps : [0,1,2,3]
    jobgraph : [
      "0 -> 1",
      "0 -> 2",
      "2 -> 3",
      "1 -> 3"
    ]
  }
]

# This workflow is crafted with s.t. the jobgraph contains nodes not present in
# the system
workflows3 : [
  {
    id : 2
    name : "Another sample process"
    description : "Reads from file, processed them and finally read them"
    steps : [0,1,2,3]
    jobgraph : [
      "0 -> 1",
      "0 -> 2",
      "2 -> 3",
      "1 -> 9"
    ]
  }
]

