# Definition of a step
#
# Properties:
#
# id          - this has to be unique
# name        - just a string
# description - need i say more ?
# workdir     - this is where the job will read the input(s) and write to; override with something at runtime.
# sessionid   - this is the identifier for the session
# inputs      - an array of strings where each input is described as "<url>:<type of input>"
# outputs     - an array of strings where each output is described as "<url>:<type of output>"
# urls        - its really an abstraction to allow the user to define a set of URLs to
# be populated into the 'inputs' and/or 'outputs'.
#
# Dynamic properties:
#
# (a) The "cliargs" would be injected with a callback URL like below so that
#     the executing jobs can use it to send back the Google Dataflow Id issued
#     for the purpose of monitoring it.
#
#     --callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId> <----- omit from configuration
#
# Note: a convention is to place variables that can be read from the ENV to be
# capitalized, hence that's how it is here.
#

#
# !!!! The configuration file here is needed for [[EngineActorSpecs.scala]] ONLY !!!!!
#  
# NOTE:
# (a) the "workdir" should be pointing to where the python scripts is/are hosted
# (b) the "workdir" should be pointing to root where the java-based programs
#     are expected to look for resources.
#
jobs_for_engine_actor_specs : [
  {
    id : 7
    name : "Job-A (Print OS environment variables)"
    description : "Job-A"
    workdir : "target/scala-2.12/test-classes"
    workdir : ${?JOB_WORK_DIR}
    sessionid : "TEST_ID_0"
    sessionid : ${?SESSION_ID}

    runner {
      module : "job_a"
      runner : "Dataflow:python"
      cliargs : ["--jobName raymond-jobgraph-test-0",
                 "--input gs://hicoden/README.md",
                 "--output gs://hicoden-test-1/XX",
                 "--runner DataflowRunner",
                 "--project hicoden",
                 "--temp_location gs://hicoden-test-1/"
                ]
      cliargs : ${?CLI_ARGS}
    }

    inputs : [ ]

    outputs : [ ]
  },

  {
    id : 8
    name : "Job-B"
    description : "Job-B"
    workdir : "target/scala-2.12/test-classes"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_1"
    sessionid: ${?SESSION_ID}

    runner {
      module : "./job_b.sh"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--numWorkers=2",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-jobgraph-test-1",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }

    inputs : [ ]

    outputs : [ ]
  },

  {
    id : 9
    name : "Job-C"
    description : "Job-C"
    workdir : "target/scala-2.12/test-classes"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_2"
    sessionid: ${?SESSION_ID}

    runner {
      module : "./job_c.sh"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-jobgraph-test-2",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }

    inputs : [ ]

    outputs : [ ]
  },

  {
    id : 10
    name : "Job-D"
    description : "Job-D"
    workdir : "target/scala-2.12/test-classes"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}

    runner {
      module : "./job_d.sh"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-jobgraph-test-3",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }

    inputs : [ ]

    outputs : [ ]
  }
]

