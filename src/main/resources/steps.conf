# Definition of a job
#
# Properties:
#
# id          - this has to be unique
# name        - just a string
# description - describe something meaningful about the job
# workdir     - this is where the job will read the input(s) and write to; override with something at runtime.
# sessionid   - this is the identifier for the session
# timeout     - a <number> in terms of minutes
# restart.max   - <number> i.e. max retries
# inputs      - an array of strings where each input is described as "<url>:<type of input>"
# outputs     - an array of strings where each output is described as "<url>:<type of output>"
#
# Dynamic properties:
#
# (a) The "cliargs" would be injected with a callback URL like below so that
#     the executing jobs can use it to send back the Google Dataflow Id issued
#     for the purpose of monitoring it.
#
#     --callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId> <----- omitted from configuration, injected at runtime
#
# Note: a convention is to place variables that can be read from the ENV to be
# capitalized, hence that's how it is here.
#

jobs : [
  {
    id : 0
    name : "Read from Data File."
    description : "blah blah blah reading a file."
    workdir : ${?HOME}"/working_dir"
    workdir : ${?JOB_WORK_DIR}
    sessionid : "TEST_ID_0"
    sessionid : ${?SESSION_ID}
    timeout : 5
    restart.max = 2

    # python -m apache_beam.examples.wordcount
    #        --jobName bloody-google-dataflow
    #        --input gs://hicoden/README.md
    #        --output gs://hicoden-test-1/XX
    #        --runner DataflowRunner
    #        --project hicoden
    #        --temp_location gs://hicoden-test-1/

    runner {
      module : "apache_beam.examples.wordcount"
      runner : "Dataflow:python"
      cliargs : ["--jobName raymond-jobgraph-test-0",
                 "--input gs://hicoden/README.md",
                 "--output gs://hicoden-test-1/XX",
                 "--runner DataflowRunner",
                 "--project hicoden",
                 "--temp_location gs://hicoden-test-1/temp/"
                ]
      cliargs : ${?CLI_ARGS}
    }

  },

  {
    id : 1
    name : "Find words that start with 'a'"
    description : "Find words that start with 'a'"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_1"
    sessionid: ${?SESSION_ID}
    timeout : 5
    restart.max = 2

    # The executable "wordcount" is produced via `sbt-pack`
    # <install dir>/bin/wordcount
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=raymond-scio-test-2
    #   --runner=DataflowRunner
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/home/hicoden/wordcount-0.1.0-SNAPSHOT/bin/wordcount"
      runner : "MesosDataflow:java"
      cliargs: [
        "--project=hicoden",
        "--numWorkers=2",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-jobgraph-test-1",
        "--runner=DataflowRunner",
        "--tempLocation=gs://hicoden-test-1/temp/",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }

  },

  {
    id : 2
    name : "Find words that start with 'b'"
    description : "Find words that start with 'b'"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_2"
    sessionid: ${?SESSION_ID}
    timeout : 5
    restart.max = 2

    # The executable "wordcount" is produced via `sbt-pack`
    # <install dir>/bin/wordcount
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=raymond-scio-test-2
    #   --runner=DataflowRunner
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/home/hicoden/wordcount-0.1.0-SNAPSHOT/bin/wordcount"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-jobgraph-test-2",
        "--tempLocation=gs://hicoden-test-1/temp/",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }

  },

  {
    id : 3
    name : "Combine words that start with 'a' and 'b'"
    description : "Combine words that start with 'a' and 'b'"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}
    timeout : 5
    restart.max = 2

    # The executable "wordcount" is produced via `sbt-pack`
    # <install dir>/bin/wordcount
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=raymond-scio-test-2
    #   --runner=DataflowRunner
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/home/hicoden/wordcount-0.1.0-SNAPSHOT/bin/wordcount"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-jobgraph-test-3",
        "--runner=DataflowRunner",
        "--tempLocation=gs://hicoden-test-1/temp/",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }

  },

  {
    id : 4
    name : "dfp.entry.ExtractStdReportAndSecQueries"
    description : "Extract Standard Report and Sec Queries"
    workdir: ${?HOME}"/hicoden/dfp-1.0.0"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "SOME_SESSION_ID"
    sessionid: ${jobgraph.settings.sessionid}
    timeout : 5
    restart.max = 2

    # The executable "startup.sh" is produced via `maven`
    # <install dir>/bin/startup.sh
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=DFP-test-run-01
    #   --runner=DataflowRunner
    #   --dataUID=102548119667364157873---751815071
    #   --startDate=2018-05-07
    #   --endDate=2018-05-13
    #   --tempLocation=gs://nugit-dfp-test/temp/
    #   --nugitType=dfp_key_metrics
    #   --standardReportPath=gs://nugit-dfp-test/out/KeyMetricsReport.csv
    #   --idsPath=gs://nugit-dfp-test/out/
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/home/hicoden/dfp-1.0.0/bin/startup.sh"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=DFP-test-run-01",
        "--runner=DataflowRunner",
        "--dataUID=102548119667364157873---751815071",
        "--startDate=2018-05-07",
        "--endDate=2018-05-13",
        "--tempLocation=gs://nugit-dfp-test/temp/",
        "--nugitType=dfp_key_metrics",
        "--standardReportPath=gs://nugit-dfp-test/out/KeyMetricsReport.csv",
        "--idsPath=gs://nugit-dfp-test/out/",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
    }
  }
]

#
# Place your common settings here and refer directly in each individual jobs
#
jobgraph.settings {
  workdir :  ${?HOME}"/working_dir"
  sessionid : "some_session_id"
  sessionid : ${?SESSION_ID}
}


