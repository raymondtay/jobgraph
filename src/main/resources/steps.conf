# Definition of a step
#
# Properties:
#
# id - this has to be unique
# name - just a string
# description - need i say more ?
# workdir - this is where the job will read the input(s) and write to; override with something at runtime.
# sessionid - this is the identifier for the session
# inputs - an array of strings where each input is described as "<url>:<type of input>"
# outputs - an array of strings where each output is described as "<url>:<type of output>"
# urls - its really an abstraction to allow the user to define a set of URLs to
# be populated into the 'inputs' and/or 'outputs'.
#
# Note: a convention is to place variables that can be read from the ENV to be
# capitalized, hence that's how it is here.
#

jobs : [
  {
    id : 0
    name : "Read from Data File."
    description : "blah blah blah reading a file."
    workdir : ${?HOME}"/working_dir"
    workdir : ${?JOB_WORK_DIR}
    sessionid : "TEST_ID_0"
    sessionid : ${?SESSION_ID}

    # python -m apache_beam.examples.wordcount
    #        --jobName bloody-google-dataflow
    #        --input gs://hicoden/README.md
    #        --output gs://hicoden-test-1/XX
    #        --runner DataflowRunner
    #        --project hicoden
    #        --temp_location gs://hicoden-test-1/
    #        --callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>

    runner {
      module : "apache_beam.examples.wordcount"
      runner : "Dataflow:python"
      cliargs : ["--jobName bloody-google-dataflow",
                 "--input gs://hicoden/README.md",
                 "--output gs://hicoden-test-1/XX",
                 "--runner DataflowRunner",
                 "--project hicoden",
                 "--temp_location gs://hicoden-test-1/",
                 "--callback http://0.0.0.0:9000/flow/<wfId>/job/<jobId>"
                ]
      cliargs : ${?CLI_ARGS}
    }
  
    inputs : [
      ${jobgraph.settings.urls.0}":local_file"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.1}":local_file"
    ]
  },

  {
    id : 1
    name : "Find words that start with 'a'"
    description : "Find words that start with 'a'"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_1"
    sessionid: ${?SESSION_ID}
 
    # The executable "wordcount" is produced via `sbt-pack`
    # <install dir>/bin/wordcount
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=raymond-scio-test-2
    #   --runner=DataflowRunner
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/some/path/to/the/executable file"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-scio-test-2",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }
  
    inputs : [
      ${jobgraph.settings.urls.2}":local_file"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.3}":local_file"
    ]
  },

  {
    id : 2
    name : "Find words that start with 'b'"
    description : "Find words that start with 'b'"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?JOB_WORK_DIR}
    sessionid: "TEST_ID_2"
    sessionid: ${?SESSION_ID}
  
    # The executable "wordcount" is produced via `sbt-pack`
    # <install dir>/bin/wordcount
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=raymond-scio-test-2
    #   --runner=DataflowRunner
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/some/path/to/the/executable file"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-scio-test-2",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }
  
    inputs : [
      ${jobgraph.settings.urls.4}":local_file2"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.5}":local_file2"
    ]
  },

  {
    id : 3
    name : "Combine words that start with 'a' and 'b'"
    description : "Combine words that start with 'a' and 'b'"
    workdir: ${?HOME}"/working_dir"
    workdir: ${?jobgraph.settings.workdir}
    sessionid: "TEST_ID_3"
    sessionid: ${jobgraph.settings.sessionid}
  
    # The executable "wordcount" is produced via `sbt-pack`
    # <install dir>/bin/wordcount
    #   --project=hicoden
    #   --zone=asia-southeast1-b
    #   --jobName=raymond-scio-test-2
    #   --runner=DataflowRunner
    #   --output=gs://hicoden-test-1/scio-output/

    runner {
      module : "/some/path/to/the/executable file"
      runner : "Dataflow:java"
      cliargs: [
        "--project=hicoden",
        "--zone=asia-southeast1-b",
        "--jobName=raymond-scio-test-2",
        "--runner=DataflowRunner",
        "--output=gs://hicoden-test-1/scio-output/"
      ]
      cliargs: ${?CLI_ARGS}
    }
  
    inputs : [
      ${jobgraph.settings.urls.6}":local_file3"
    ]
  
    outputs : [
      ${jobgraph.settings.urls.7}":local_file3"
    ]
  }
]

#
# Place your common settings here and refer directly in each individual jobs
#
jobgraph.settings {
  workdir :  ${?HOME}"/working_dir"
  sessionid : "some_session_id"
  sessionid : ${?SESSION_ID}
  urls.0 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/input_data0" 
  urls.1 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/output_data0" 
  urls.2 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/input_data1" 
  urls.3 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/input_data1" 
  urls.4 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/output_data2" 
  urls.5 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/output_data2" 
  urls.6 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/output_data3" 
  urls.7 : ${jobgraph.settings.workdir}"/"${jobgraph.settings.sessionid}"/output_data3" 
}
